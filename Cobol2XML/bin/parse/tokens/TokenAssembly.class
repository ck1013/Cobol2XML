import java.util.Stack;
import parse.tokens.*;

/**
 * The TokenAssembly class is used to manage the consumption and un-consumption of tokens from a Tokenizer.
 * It maintains a buffer of consumed tokens and a stack of lengths of those tokens, allowing for easy
 * un-consumption of the most recently consumed token.
 */
public class TokenAssembly {
    private String delimiter; // The delimiter used to separate consumed tokens in the string representation
    private StringBuffer buf; // A buffer to store the consumed tokens
    private Stack elementsConsumed; // A stack to store the lengths of the consumed tokens
    private Tokenizer tokenizer; // The Tokenizer providing the tokens
    private String remainder; // The remainder of the current token, if any
    private int index; // The index of the current token in the Tokenizer

    /**
     * Constructs a new TokenAssembly instance with the given delimiter and Tokenizer.
     * @param delimiter The delimiter used to separate consumed tokens in the string representation
     * @param tokenizer The Tokenizer providing the tokens
     */
    public TokenAssembly(String delimiter, Tokenizer tokenizer) {
        this.delimiter = delimiter;
        this.tokenizer = tokenizer;
        this.buf = new StringBuffer();
        this.elementsConsumed = new Stack();
        this.remainder = "";
        this.index = 0;
    }

    /**
     * Consumes the next token from the Tokenizer and appends it to the buffer.
     * @return The first character of the consumed token
     */
    public String consume() {
        String tokenString = tokenizer.getToken(index).toString();
        int length = tokenString.length();
        buf.append(tokenString);
        elementsConsumed.push(new Integer(length));
        index += length;
        remainder = tokenString.substring(1);
        return tokenString.substring(0, 1);
    }

    /**
     * Returns the current contents of the buffer.
     * @return The current contents of the buffer
     */
    public String consumed() {
        return buf.toString();
    }

    /**
     * Un-consumes the most recently consumed token by popping its length from the stack and adjusting the index.
     */
    public void unconsume() {
        Integer len = (Integer) elementsConsumed.pop();
        index -= len.intValue();
        remainder = tokenizer.getToken(index).toString();
        buf.setLength(buf.length() - len.intValue());
    }

    /**
     * Returns true if there are more tokens in the Tokenizer, false otherwise.
     * @return True if there are more tokens in the Tokenizer, false otherwise
     */
    public boolean hasMoreTokens() {
        return index < tokenizer.size();
    }

    /**
     * Returns the next token from the Tokenizer or the remainder of the current token if it has not been fully consumed.
     * @return The next token from the Tokenizer or the remainder of the current token
     */
    public String peek() {
        if (remainder.length() > 0) {
            return remainder;
        }
        return tokenizer.getToken(index).toString();
    }

    /**
     * Returns the next element from the Tokenizer, which may be the remainder of the current token or a new token.
     * @return The next element from the Tokenizer
     */
    public String nextElement() {
        if (remainder.length() > 0) {
            String result = remainder;
            remainder = "";
            return result;
        }
        Token token = tokenizer.getToken(index);
        int start = index;
        index += token.length();
        return token.toString();
    }

    /**
     * Returns a string representation of the consumed tokens,
